{
 "cells": [
  {
   "cell_type": "code",
   "id": "8ab020b3d49e309d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:13:19.108857Z",
     "start_time": "2025-08-07T03:13:17.571250Z"
    }
   },
   "source": [
    "!pip install sentencepiece\n",
    "!pip install transformers\n",
    "!pip install datasets"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (0.2.0)\r\n",
      "Requirement already satisfied: transformers in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (4.54.1)\r\n",
      "Requirement already satisfied: filelock in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from transformers) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from transformers) (0.34.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from transformers) (2.3.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from transformers) (2025.7.34)\r\n",
      "Requirement already satisfied: requests in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from transformers) (2.32.4)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from transformers) (0.21.4)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.12.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from requests->transformers) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from requests->transformers) (2025.7.14)\r\n",
      "Requirement already satisfied: datasets in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (3.3.2)\r\n",
      "Requirement already satisfied: filelock in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from datasets) (3.18.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from datasets) (2.3.1)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from datasets) (19.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from datasets) (2.3.1)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from datasets) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from datasets) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from datasets) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from datasets) (0.70.15)\r\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\r\n",
      "Requirement already satisfied: aiohttp in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from datasets) (3.11.10)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from datasets) (0.34.3)\r\n",
      "Requirement already satisfied: packaging in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from datasets) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from datasets) (6.0.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from aiohttp->datasets) (24.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.0)\r\n",
      "Requirement already satisfied: idna>=2.0 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.7)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.7.14)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/George/miniconda3/envs/MLXTraining/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:13:20.015110Z",
     "start_time": "2025-08-07T03:13:19.168545Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlx.optimizers as optim\n",
    "from mlx.utils import tree_flatten\n",
    "from mlx_lm import generate, load\n",
    "from mlx_lm.tuner import TrainingArgs, datasets, linear_to_lora_layers, train\n",
    "from transformers import PreTrainedTokenizer"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "8fa45f9a21ddff75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:13:20.546849Z",
     "start_time": "2025-08-07T03:13:20.020910Z"
    }
   },
   "source": [
    "import sentencepiece\n",
    "model_path = \"mlx-community/Mistral-7B-Instruct-v0.3-4bit\"\n",
    "#model_path = \"mlx-community/Phi-3.5-mini-instruct-8bit\"\n",
    "model, tokenizer = load(model_path)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33ed4e689ba64b86b3ad853b8cbb9ace"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "56096efcd24fb024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:13:23.562084Z",
     "start_time": "2025-08-07T03:13:20.554576Z"
    }
   },
   "source": [
    "prompt = \"Express in SQL. What is background color of Australian capital territory?\"\n",
    "\n",
    "if tokenizer.chat_template is not None:\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "response = generate(model, tokenizer, prompt=prompt, verbose=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "SQL (Structured Query Language) is a programming language used for managing and manipulating relational databases. It does not have the capability to set or retrieve the background color of a geographical region like the Australian Capital Territory (ACT). SQL is used for database operations such as creating, updating, and querying data in a database. If you have data related to the ACT and want to retrieve it, you can use SQL for that purpose. For example, you can query for the population, area, or other attributes of the ACT. However, to set or retrieve the background color of a geographical region, you would need a different programming language or tool that can interact with a Graphics User Interface (GUI) or a mapping software.\n",
      "==========\n",
      "Prompt: 18 tokens, 137.157 tokens-per-sec\n",
      "Generation: 153 tokens, 55.126 tokens-per-sec\n",
      "Peak memory: 4.158 GB\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "992d545cf8b156ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:13:23.573156Z",
     "start_time": "2025-08-07T03:13:23.568592Z"
    }
   },
   "source": [
    "adapter_path = \"adapters\"\n",
    "os.makedirs(adapter_path, exist_ok=True)\n",
    "adapter_config_path = os.path.join(adapter_path, \"adapter_config.json\")\n",
    "adapter_file_path = os.path.join(adapter_path, \"adapters.safetensors\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "a642f9fc43b15ca0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:13:23.592666Z",
     "start_time": "2025-08-07T03:13:23.589904Z"
    }
   },
   "source": [
    "lora_config = {\n",
    "    \"num_layers\": 10,\n",
    "    \"lora_parameters\": {\n",
    "        \"rank\": 10,\n",
    "        \"scale\": 20,\n",
    "        \"dropout\": 0.4,\n",
    "        \"target_modules\": [\n",
    "        \"self_attn.q_proj\",\n",
    "        \"self_attn.v_proj\",\n",
    "#        \"self_attn.k_proj\",\n",
    "#        \"self_attn.o_proj\"\n",
    "    ],\n",
    "    },\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "a6a999664b620e2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:13:23.604503Z",
     "start_time": "2025-08-07T03:13:23.602437Z"
    }
   },
   "source": [
    "with open(adapter_config_path, \"w\") as f:\n",
    "    json.dump(lora_config, f, indent=4)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "cbcf1118650355d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:13:23.615598Z",
     "start_time": "2025-08-07T03:13:23.613936Z"
    }
   },
   "source": [
    "training_args = TrainingArgs(\n",
    "    adapter_file=adapter_file_path,\n",
    "    iters=200,\n",
    "    steps_per_eval=50,\n",
    "    batch_size=4,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "3a7ded557bc864f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:13:23.633827Z",
     "start_time": "2025-08-07T03:13:23.625346Z"
    }
   },
   "source": [
    "model.freeze()\n",
    "linear_to_lora_layers(model, lora_config[\"num_layers\"], lora_config[\"lora_parameters\"])\n",
    "num_train_params = sum(v.size for _, v in tree_flatten(model.trainable_parameters()))\n",
    "print(f\"Number of trainable parameters: {num_train_params}\")\n",
    "model.train()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 1331200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): QuantizedEmbedding(32768, 4096, group_size=64, bits=4)\n",
       "    (layers.0): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.1): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.2): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.3): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.4): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.5): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.6): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.7): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.8): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.9): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.10): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.11): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.12): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.13): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.14): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.15): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.16): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.17): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.18): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.19): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.20): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.21): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.22): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.23): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.24): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.25): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.26): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.27): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.28): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.29): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.30): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (layers.31): TransformerBlock(\n",
       "      (self_attn): Attention(\n",
       "        (q_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (k_proj): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "        (v_proj): LoRALinear(\n",
       "          (linear): QuantizedLinear(input_dims=4096, output_dims=1024, bias=False, group_size=64, bits=4)\n",
       "          (dropout): Dropout(p=0.4)\n",
       "        )\n",
       "        (o_proj): QuantizedLinear(input_dims=4096, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (rope): RoPE(128, traditional=False)\n",
       "      )\n",
       "      (mlp): MLP(\n",
       "        (gate_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "        (down_proj): QuantizedLinear(input_dims=14336, output_dims=4096, bias=False, group_size=64, bits=4)\n",
       "        (up_proj): QuantizedLinear(input_dims=4096, output_dims=14336, bias=False, group_size=64, bits=4)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "      (post_attention_layernorm): RMSNorm(4096, eps=1e-05)\n",
       "    )\n",
       "    (norm): RMSNorm(4096, eps=1e-05)\n",
       "  )\n",
       "  (lm_head): QuantizedLinear(input_dims=4096, output_dims=32768, bias=False, group_size=64, bits=4)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "e53ccbc2ab77382e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:13:23.640703Z",
     "start_time": "2025-08-07T03:13:23.637423Z"
    }
   },
   "source": [
    "class Metrics:\n",
    "    def __init__(self) -> None:\n",
    "        self.train_losses: List[Tuple[int, float]] = []\n",
    "        self.val_losses: List[Tuple[int, float]] = []\n",
    "\n",
    "    def on_train_loss_report(self, info: Dict[str, Union[float, int]]) -> None:\n",
    "        self.train_losses.append((info[\"iteration\"], info[\"train_loss\"]))\n",
    "\n",
    "    def on_val_loss_report(self, info: Dict[str, Union[float, int]]) -> None:\n",
    "        self.val_losses.append((info[\"iteration\"], info[\"val_loss\"]))"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "716901cfaf71a865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:13:23.648007Z",
     "start_time": "2025-08-07T03:13:23.646705Z"
    }
   },
   "source": [
    "metrics = Metrics()"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "56bc9ca9e033f400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:13:24.401711Z",
     "start_time": "2025-08-07T03:13:23.657801Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "def custom_load_hf_dataset(\n",
    "    data_id: str,\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "    config: TrainingArgs = None,\n",
    "    names: Tuple[str, str, str] = (\"train\", \"valid\", \"test\"),\n",
    "):\n",
    "\n",
    "\n",
    "    # Use default config if none provided\n",
    "    if config is None:\n",
    "        config = TrainingArgs()\n",
    "\n",
    "    # Load the dataset from Hugging Face\n",
    "    dataset = load_dataset(data_id)\n",
    "\n",
    "    train, valid, test = [\n",
    "        (\n",
    "            datasets.create_dataset(dataset[n], tokenizer, config)\n",
    "            if n in dataset.keys()\n",
    "            else []\n",
    "        )\n",
    "            for n in names\n",
    "    ]\n",
    "\n",
    "\n",
    "    return train, valid, test"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "866e5ee203d7fb65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:13:25.243237Z",
     "start_time": "2025-08-07T03:13:24.408837Z"
    }
   },
   "source": [
    "train_set, val_set, test_set = custom_load_hf_dataset(\n",
    "    data_id=\"mlx-community/wikisql\",\n",
    "    tokenizer=tokenizer,\n",
    "    names=(\"train\", \"valid\", \"test\")\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "743a6ff112619249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:22:23.544560Z",
     "start_time": "2025-08-07T03:13:25.255136Z"
    }
   },
   "source": [
    "from mlx_lm.tuner.datasets import load_dataset, CacheDataset\n",
    "train(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    optimizer=optim.AdamW(learning_rate=5e-5),\n",
    "    train_dataset=CacheDataset(train_set),\n",
    "    val_dataset=CacheDataset(val_set),\n",
    "    training_callback=metrics,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training..., iters: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating loss...: 100%|| 25/25 [00:35<00:00,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1: Val loss 2.502, Val took 35.971s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10: Train loss 1.789, Learning Rate 5.000e-05, It/sec 0.538, Tokens/sec 202.663, Trained Tokens 3764, Peak mem 5.996 GB\n",
      "Iter 20: Train loss 1.448, Learning Rate 5.000e-05, It/sec 0.484, Tokens/sec 207.216, Trained Tokens 8043, Peak mem 6.001 GB\n",
      "Iter 30: Train loss 1.434, Learning Rate 5.000e-05, It/sec 0.536, Tokens/sec 220.016, Trained Tokens 12146, Peak mem 6.001 GB\n",
      "Iter 40: Train loss 1.368, Learning Rate 5.000e-05, It/sec 0.593, Tokens/sec 222.513, Trained Tokens 15898, Peak mem 6.001 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating loss...: 100%|| 25/25 [00:36<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 50: Val loss 1.260, Val took 36.223s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 50: Train loss 1.342, Learning Rate 5.000e-05, It/sec 0.591, Tokens/sec 223.245, Trained Tokens 19673, Peak mem 6.001 GB\n",
      "Iter 60: Train loss 1.161, Learning Rate 5.000e-05, It/sec 0.568, Tokens/sec 217.601, Trained Tokens 23505, Peak mem 6.001 GB\n",
      "Iter 70: Train loss 1.210, Learning Rate 5.000e-05, It/sec 0.624, Tokens/sec 217.058, Trained Tokens 26981, Peak mem 6.001 GB\n",
      "Iter 80: Train loss 1.202, Learning Rate 5.000e-05, It/sec 0.521, Tokens/sec 216.273, Trained Tokens 31130, Peak mem 6.002 GB\n",
      "Iter 90: Train loss 1.138, Learning Rate 5.000e-05, It/sec 0.607, Tokens/sec 224.223, Trained Tokens 34821, Peak mem 6.002 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating loss...: 100%|| 25/25 [00:35<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100: Val loss 1.146, Val took 35.387s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100: Train loss 1.120, Learning Rate 5.000e-05, It/sec 0.524, Tokens/sec 214.231, Trained Tokens 38910, Peak mem 6.002 GB\n",
      "Iter 100: Saved adapter weights to adapters/adapters.safetensors and adapters/0000100_adapters.safetensors.\n",
      "Iter 110: Train loss 0.947, Learning Rate 5.000e-05, It/sec 0.537, Tokens/sec 212.654, Trained Tokens 42871, Peak mem 6.007 GB\n",
      "Iter 120: Train loss 1.144, Learning Rate 5.000e-05, It/sec 0.540, Tokens/sec 223.006, Trained Tokens 47004, Peak mem 6.007 GB\n",
      "Iter 130: Train loss 1.130, Learning Rate 5.000e-05, It/sec 0.567, Tokens/sec 236.431, Trained Tokens 51171, Peak mem 6.575 GB\n",
      "Iter 140: Train loss 0.988, Learning Rate 5.000e-05, It/sec 0.526, Tokens/sec 213.093, Trained Tokens 55219, Peak mem 6.575 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating loss...: 100%|| 25/25 [00:35<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 150: Val loss 1.103, Val took 35.085s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 150: Train loss 1.038, Learning Rate 5.000e-05, It/sec 0.567, Tokens/sec 220.157, Trained Tokens 59103, Peak mem 6.575 GB\n",
      "Iter 160: Train loss 1.154, Learning Rate 5.000e-05, It/sec 0.541, Tokens/sec 208.090, Trained Tokens 62950, Peak mem 6.575 GB\n",
      "Iter 170: Train loss 1.085, Learning Rate 5.000e-05, It/sec 0.569, Tokens/sec 233.598, Trained Tokens 67052, Peak mem 6.575 GB\n",
      "Iter 180: Train loss 1.207, Learning Rate 5.000e-05, It/sec 0.585, Tokens/sec 229.000, Trained Tokens 70965, Peak mem 6.575 GB\n",
      "Iter 190: Train loss 1.019, Learning Rate 5.000e-05, It/sec 0.569, Tokens/sec 227.893, Trained Tokens 74967, Peak mem 6.575 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating loss...: 100%|| 25/25 [00:35<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 200: Val loss 1.064, Val took 35.043s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 200: Train loss 1.100, Learning Rate 5.000e-05, It/sec 0.554, Tokens/sec 215.578, Trained Tokens 78859, Peak mem 6.597 GB\n",
      "Iter 200: Saved adapter weights to adapters/adapters.safetensors and adapters/0000200_adapters.safetensors.\n",
      "Saved final weights to adapters/adapters.safetensors.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:22:23.624933Z",
     "start_time": "2025-08-07T03:22:23.556271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_its, train_losses = zip(*metrics.train_losses)\n",
    "validation_its, validation_losses = zip(*metrics.val_losses)\n",
    "plt.plot(train_its, train_losses, \"-o\", label=\"Train\")\n",
    "plt.plot(validation_its, validation_losses, \"-o\", label=\"Validation\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "ca1ccb402534e46f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:22:24.081061Z",
     "start_time": "2025-08-07T03:22:23.635452Z"
    }
   },
   "cell_type": "code",
   "source": "model_lora, _ = load(model_path, adapter_path=adapter_path)",
   "id": "39b847cfb88c41b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f59c66a4c9a94b3b81e6e23a7e75d2fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:22:26.497475Z",
     "start_time": "2025-08-07T03:22:24.089600Z"
    }
   },
   "cell_type": "code",
   "source": "response = generate(model_lora, tokenizer, prompt=prompt, verbose=True)",
   "id": "4cd383d3f1d572b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "SQL is a table-based, row-oriented, and table-oriented language used for managing and manipulating databases. It is not used for querying the background color of geographical locations such as the Australian Capital Territory (ACT). The background color of the ACT is determined by the physical location of the screen, not by a database. If you have a database with the background color as a field, you could use SQL to select the background color of the ACT, but the ACT itself does not have a background color in the sense that a screen or a web page does.\n",
      "==========\n",
      "Prompt: 18 tokens, 157.168 tokens-per-sec\n",
      "Generation: 119 tokens, 52.161 tokens-per-sec\n",
      "Peak memory: 8.265 GB\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T03:29:16.730507Z",
     "start_time": "2025-08-07T03:29:13.018694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the fine-tuned model\n",
    "model_enhanced, _ = load(model_path, adapter_path=adapter_path)\n",
    "\n",
    "# Test with a sample prompt\n",
    "test_prompts = [\n",
    "    \"you are SQL translator and translate Natural Language to SQL.Now Translate:What is best city in the world?\",\n",
    "    \"you are SQL translator and translate Natural Language to SQL.how many engines we have in system is gas powered and how many is CNG?\",\n",
    "    \"you are SQL developer and express answers in SQL.What is the max gross weight of the Robinson R-22?\"\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    if tokenizer.chat_template is not None:\n",
    "#        messages = [{\"role\": \"system\", \"content\": \"you are SQL developer and express answers in SQL only.\"},{\"role\": \"user\", \"content\": prompt}]\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        formatted_prompt = tokenizer.apply_chat_template(\n",
    "            messages, add_generation_prompt=True\n",
    "        )\n",
    "    else:\n",
    "        formatted_prompt = prompt\n",
    "\n",
    "    response = generate(\n",
    "        model_enhanced,\n",
    "        tokenizer,\n",
    "        prompt=formatted_prompt,\n",
    "        max_tokens=100,\n",
    "        verbose=False\n",
    "    )\n",
    "    print(response)"
   ],
   "id": "f2f04416bfd681e4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2da39461298e4a70b792383f28c49526"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: you are SQL translator and translate Natural Language to SQL.Now Translate:What is best city in the world?\n",
      "--------------------------------------------------\n",
      "SELECT City FROM WorldCities WHERE Best = 'Yes'\n",
      "\n",
      "Prompt: you are SQL translator and translate Natural Language to SQL.how many engines we have in system is gas powered and how many is CNG?\n",
      "--------------------------------------------------\n",
      "To answer your question, we need to select the number of engines from the system where the fuel is either gas or CNG. Here's the SQL query for that:\n",
      "\n",
      "```\n",
      "SELECT COUNT EngineID FROM Engines WHERE Fuel = 'Gas' OR Fuel = 'CNG'\n",
      "\n",
      "Prompt: you are SQL developer and express answers in SQL.What is the max gross weight of the Robinson R-22?\n",
      "--------------------------------------------------\n",
      "To answer your table-free question, I'm assuming that you have a table with aircraft information. Let's say the table is called aircraft_info, and the gross weight is stored in the column 'gross_weight'.\n",
      "\n",
      "SELECT MAX gross_weight FROM aircraft_info WHERE aircraft_model = 'Robinson R-22'\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
